{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "import folium \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from folium.plugins import HeatMap\n",
    "from collections import defaultdict\n",
    "import branca.colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions for all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_POI_density_for_each_link(this_df,this_node_csv,hotspot_column_name, number_of_hotspot_users_column_name):\n",
    "    df_copy = this_df.copy()\n",
    "    \n",
    "    link_csv_POIdata = np.zeros(len(df_copy.index))\n",
    "    link_csv_integerindex = np.arange(len(df_copy))\n",
    "    link_csv_index = np.array(df_copy.index)\n",
    "    traffic_signals = np.zeros(len(df_copy.index))\n",
    "    hotspots = np.zeros(len(df_copy.index))\n",
    "    hotspot_users = np.zeros(len(df_copy.index))\n",
    "    for i in link_csv_integerindex:\n",
    "        item = link_csv_index[i]\n",
    "        link_index_v = df_copy.loc[item,'v']\n",
    "        link_index_u = df_copy.loc[item,'u']\n",
    "        # Put POI Density information\n",
    "        POI_data = this_node_csv.loc[link_index_v,'Closest Poi Density_with distance decay']\n",
    "        POI_data_2 = this_node_csv.loc[link_index_u,'Closest Poi Density_with distance decay']\n",
    "        # Each link is connected to 2 nodes. We find the POI density for each node and find the mean of the two\n",
    "        # Alternatively, we could use the max of the two\n",
    "        mean_POI = (POI_data+POI_data_2)/2\n",
    "        link_csv_POIdata[i] = mean_POI\n",
    "\n",
    "        # Put traffic signal information\n",
    "        if (this_node_csv.loc[link_index_v,'highway']=='traffic_signals')|(this_node_csv.loc[link_index_u,'highway']=='traffic_signals'):\n",
    "            traffic_signals[i]=1\n",
    "        else:\n",
    "            traffic_signals[i]=0\n",
    "\n",
    "        # Put hotspot information\n",
    "        # We find the number of users for each link by finding the num of users for the nodes that touch the link \n",
    "        # Then we get the maximum number of users \n",
    "        if (this_node_csv.loc[link_index_v,hotspot_column_name]==1)|(this_node_csv.loc[link_index_u,hotspot_column_name]==1):\n",
    "            hotspots[i]=1\n",
    "        num_of_users_in_node_v = this_node_csv.loc[link_index_v,number_of_hotspot_users_column_name]\n",
    "        num_of_users_in_node_u = this_node_csv.loc[link_index_u,number_of_hotspot_users_column_name]\n",
    "        max_hotspot_users = np.max(np.array([num_of_users_in_node_v,num_of_users_in_node_u]))\n",
    "        hotspot_users[i]=max_hotspot_users\n",
    "\n",
    "    df_copy['Closest Poi Density_with distance decay']=link_csv_POIdata\n",
    "    df_copy['Closest Poi Density_with distance decay'] = df_copy['Closest Poi Density_with distance decay'].fillna(0)\n",
    "    df_copy['Traffic signals']=traffic_signals\n",
    "\n",
    "    # These two columns are used so that we can include existing physiological data for this city\n",
    "    df_copy['Hotspot']=hotspots\n",
    "    df_copy['Hotspot users']=hotspot_users\n",
    "    return(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a column representing the time needed to walk on each link (street segment) from start to end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_attribute(this_df,this_walking_speed):\n",
    "    travel_speed = this_walking_speed\n",
    "    #transform km per hour to m per minute\n",
    "    meters_per_minute = travel_speed * 1000 / 60 \n",
    "    this_df['time'] = 0\n",
    "    this_df['time'] = this_df['length'] / meters_per_minute\n",
    "    return(this_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make a df with selected columns for route optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A definition to create the df with selected attributes\n",
    "def create_csv_with_selected_attributes_for_optimisation(this_df):\n",
    "    new_df = pd.DataFrame(this_df,columns=['u','v','traffic', 'length','Closest Poi Density_with distance decay', 'Traffic signals','time','Hotspot', 'Hotspot users'])\n",
    "    new_df.loc[new_df[new_df['Closest Poi Density_with distance decay']==0].index,'Closest Poi Density_with distance decay']=1\n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data transformation: Transform the selected attributes to fit in the same scale (0.1-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_attributes(this_df, attribute_name, scaled_attribute_name):\n",
    "    attribute_data = this_df[attribute_name]\n",
    "    attribute_arr = np.reshape(np.array(attribute_data), (-1, 1))\n",
    "    this_scaler = MinMaxScaler(copy=True, feature_range=(0.1, 1))\n",
    "    this_scaler.fit(attribute_arr)\n",
    "    attribute_arr = this_scaler.transform(attribute_arr)\n",
    "    this_df[scaled_attribute_name]=attribute_arr\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put modifiers for each attribute \n",
    "If we want all the criteria to have the same importance, we can set the modifier value to 1 for all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_modifiers_in_the_attributes(this_df, length_m,traffic_m,density_m,traffic_signal_m,hotspot_m):\n",
    "    # Create one column that sums the attributes for each link, after applying the modifiers\n",
    "    this_df['Combined attributes'] = length_m*this_df['scaled Length']+traffic_m*this_df['scaled Traffic']+density_m*this_df['scaled Density'] + traffic_signal_m*this_df['scaled Signals'] \n",
    "    this_df['Combined attributes']=this_df['Combined attributes'].astype('int32')\n",
    "    # Create another column which includes all other attributes and the hotspot attribute as well (in case we want to use this in the optimisation)\n",
    "    \n",
    "    this_df['Combined attributes and Hotspots']=length_m*this_df['scaled Length']+traffic_m*this_df['scaled Traffic']+density_m*this_df['scaled Density'] + traffic_signal_m*this_df['scaled Signals'] + hotspot_m*this_df['scaled Hotspot']\n",
    "    this_df['Combined attributes and Hotspots']=this_df['Combined attributes and Hotspots'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_seconds(speed, dist):\n",
    "    tm = dist/(speed*1000)\n",
    "    tm = tm*60*60\n",
    "    return(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ------  DEFINITIONS FOR EACH SCENARIO ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEFINITIONS FOR SCENARIO A\n",
    "Find the shortest path based on all criteria (or only selected ones) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shortest_path_ScenarioA(this_graph, start, destination, attribute):\n",
    "    shortest_path = nx.shortest_path(this_graph, source=start, target=destination, weight=attribute, method='dijkstra')\n",
    "    # This returns a list of nodes from the node_csv, corresponding to the shortest path according to the \n",
    "    # selected criterion\n",
    "    return(shortest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### DEFINITIONS FOR SCENARIO D \n",
    "(The scenario that includes isochrones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create isochrones for a range of trip duration times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_isochrones(this_graph, trip_time_list,this_node,visualise_isochrones_on_map,\n",
    "                     length_m,traffic_m,density_m,traffic_signal_m,hotspot_m):\n",
    "    \n",
    "    #The isochrone tutorial was found here:\n",
    "    #https://github.com/gboeing/osmnx-examples/blob/master/notebooks/13-isolines-isochrones.ipynb\n",
    "    \n",
    "    # We will put a ranking in each node and edge, according to time needed to reach it from our central node\n",
    "    #Also, create a dict for visualisation, containing one colour for each node based on the time needed to reach it from the target node\n",
    "    \n",
    "    edge_isochrones = {}\n",
    "    node_colors = {}\n",
    "    time_ranks = {}\n",
    "    iso_colors = ox.plot.get_colors(n=len(trip_time_list), cmap='plasma', start=0, return_hex=True)\n",
    "    for edge in new_G.edges:\n",
    "        edge_isochrones[edge]=1000\n",
    "\n",
    "    for trip_time, color in zip(sorted(trip_time_list, reverse=True), iso_colors):\n",
    "        subgraph = nx.ego_graph(this_graph, this_node, radius=trip_time, distance='time')\n",
    "        # This is the necessary part for computing the time-based penalty for the edge attributes\n",
    "        for edge in subgraph.edges():\n",
    "            if edge in this_graph.edges:\n",
    "                edge_isochrones[edge]=trip_time\n",
    "        # This is only needed for visualisation\n",
    "        if visualise_isochrones_on_map==True:\n",
    "            for node in subgraph.nodes():\n",
    "                node_colors[node] = str(color)\n",
    "                time_ranks[node] = trip_time\n",
    "\n",
    "    #Create a copy of the graph and add the time needed to reach each edge as an edge weight\n",
    "    new_graph = this_graph.copy()\n",
    "    nx.set_edge_attributes(new_graph, edge_isochrones, 'Edge isochrones')\n",
    "    \n",
    "    # Get the rest of the attributes \n",
    "    scaled_density_dict = nx.get_edge_attributes(new_graph,'scaled Density')\n",
    "    scaled_traffic_dict = nx.get_edge_attributes(new_graph,'scaled Traffic')\n",
    "    scaled_signal_dict = nx.get_edge_attributes(new_graph,'scaled Signals')\n",
    "    scaled_length_dict = nx.get_edge_attributes(new_graph,'scaled Length')\n",
    "    hotspot_dict = nx.get_edge_attributes(new_graph,'scaled Hotspot')\n",
    "    iso_dict = nx.get_edge_attributes(new_graph,'Edge isochrones')\n",
    "    \n",
    "    #Create a new attribute that combines all other attributes and adds a multiplier based on time\n",
    "    #The multiplier penalizes more the points that have large density etc. as time increases\n",
    "    \n",
    "    time_corrected_combined_criterion = {}\n",
    "    time_corrected_combined_with_hotspots_criterion = {}\n",
    "    for k in list(scaled_signal_dict.keys()):\n",
    "\n",
    "        m = np.power(iso_dict[k],2)\n",
    "        # In the other definition ('put_modifiers_in_the_attributes') we put only the modifiers \n",
    "        # Now we also include another modifier (m) based on the isochrone values\n",
    "        \n",
    "        # This is for D without hotspot inclusion\n",
    "        combined = length_m*scaled_length_dict[k] + traffic_signal_m*scaled_signal_dict[k]*m + density_m*scaled_density_dict[k]*m + traffic_m*scaled_traffic_dict[k]*m\n",
    "        \n",
    "        # This is for scenario B+D, where we also include the hotspots in the computation\n",
    "        combined_with_hotspots = length_m*scaled_length_dict[k] + traffic_signal_m*scaled_signal_dict[k]*m + density_m*scaled_density_dict[k]*m + traffic_m*scaled_traffic_dict[k]*m + hotspot_m*hotspot_dict[k]*m\n",
    "        \n",
    "        \n",
    "        time_corrected_combined_criterion[k]=combined\n",
    "        time_corrected_combined_with_hotspots_criterion[k]=combined_with_hotspots\n",
    "    nx.set_edge_attributes(new_graph, time_corrected_combined_criterion, 'Time-corrected combined attributes')\n",
    "    nx.set_edge_attributes(new_graph, time_corrected_combined_with_hotspots_criterion, 'Time-corrected combined attributes with hotspots')\n",
    "    \n",
    "    \n",
    "    # return the copy of the graph with the isochrone attributes\n",
    "    return([new_graph,node_colors,time_ranks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate time needed to walk each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this path: the route for which we want to calculate time\n",
    "def calculate_route_time(this_path, walking_speed):\n",
    "    this_route_time = 0\n",
    "    \n",
    "    for i in range(0, len(this_path)-1):\n",
    "        start = this_path[i]\n",
    "        end = this_path[i+1]\n",
    "        if len(link_csv_for_nx[(link_csv_for_nx['u']==start)&(link_csv_for_nx['v']==end)])!=0:\n",
    "            this_df = link_csv_for_nx[(link_csv_for_nx['u']==start)&(link_csv_for_nx['v']==end)]\n",
    "            this_length = this_df['length']\n",
    "            this_route_time = this_route_time+calculate_seconds(walking_speed, this_length.values[0])\n",
    "\n",
    "    print('Route time: ' + str(int(this_route_time/60)) + ' minutes')\n",
    "    # The function returns route time in minutes\n",
    "    return(int(this_route_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------ Definitions for visualisation ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we have only 1 created path: Visualise the created path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_shortest_path(this_graph, this_title, this_path, node_colour,\n",
    "                           render_combined_stressors,node_df_for_stressors):\n",
    "    \n",
    "    this_map = ox.folium.plot_graph_folium(this_graph, graph_map=None, popup_attribute=None, tiles='cartodbpositron', zoom=1, location = [-33.8756785, 151.22353900000002],fit_bounds=True, edge_color='salmon', edge_width=0.5, edge_opacity=0.5)\n",
    "    this_map.save( this_title + \".html\" )\n",
    "\n",
    "\n",
    "    cnt=0\n",
    "\n",
    "    for item in node_list:\n",
    "\n",
    "        this_pt = (node_csv.loc[item, 'y'],node_csv.loc[item, 'x'])\n",
    "        this_radius = 0.5\n",
    "        this_opacity=0.3\n",
    "\n",
    "        this_index = 'non'\n",
    "        if item in this_path:\n",
    "            this_colour = node_colour\n",
    "            this_radius = 4\n",
    "            this_opacity=0.9\n",
    "            this_index = this_path.index(item)\n",
    "\n",
    "        if this_index!='non':\n",
    "            folium.CircleMarker([this_pt[0],this_pt[1]], color=this_colour, fill=True, radius=this_radius, \n",
    "                                opacity=this_opacity,fill_opacity = this_opacity, fill_color=this_colour,\n",
    "                       popup = str(item)+'_'+str(this_index)).add_to(this_map)\n",
    "\n",
    "    #-----RENDER ALL THE STRESSORS-----\n",
    "    if render_combined_stressors == True:\n",
    "        steps = 10\n",
    "        colormap = branca.colormap.linear.YlOrRd_09.scale(0.0, 1.5).to_step(steps)\n",
    "        gradient_map=defaultdict(dict)\n",
    "        for i in range(steps):\n",
    "            gradient_map[1/steps*i] = colormap.rgb_hex_str(1/steps*i)\n",
    "        gmap=gradient_map\n",
    "\n",
    "\n",
    "        node_df_for_stressors['Traffic signal']=0\n",
    "        node_df_for_stressors.loc[node_df_for_stressors[node_df_for_stressors['highway']=='traffic_signals'].index, 'Traffic signal']=1\n",
    "        \n",
    "        this_df = node_df_for_stressors[(node_df_for_stressors['Closest Poi Density_with distance decay']>15)|(node_df_for_stressors['traffic']>2)|(node_df_for_stressors['Traffic signal']==1)].copy()\n",
    "        # If we want to visualise only the hotspots of one stressor, delete the others, like in the following line (which should visualise only the POI density)\n",
    "        # this_df = node_df_for_stressors[node_df_for_stressors['Closest Poi Density_with distance decay']>15].copy()\n",
    "        this_df['Combined stressors']=1\n",
    "        HeatMap(data=this_df[['y', 'x', 'Combined stressors']].groupby(['y', 'x']).sum().reset_index().values.tolist(),gradient=gmap, radius=7, max_zoom=13).add_to(this_map)\n",
    "\n",
    "\n",
    "\n",
    "    this_map.save(this_title + \".html\" )\n",
    "    return(this_map)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a map to compare the generated shortest paths (if we have created many paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have generated many different paths (according to different criteria) for the same starting and ending point,\n",
    "# we can visualise them for comparison using this definition \n",
    "def create_map_for_comparison_of_generated_paths(this_graph, this_title, path_list, colour_list, criteria_list,\n",
    "                                                render_combined_stressors,node_df_for_stressors):\n",
    "    \n",
    "    this_map = ox.folium.plot_graph_folium(this_graph, graph_map=None, popup_attribute=None, tiles='cartodbpositron', zoom=1, location = [-33.8756785, 151.22353900000002],fit_bounds=True, edge_color='salmon', edge_width=0.5, edge_opacity=0.5)\n",
    "    #this_paths_map.save(\"Compare the generated shortest paths.html\" )\n",
    "    this_map.save( this_title + \".html\" )\n",
    "\n",
    "    cnt=0\n",
    "    for item in node_list:\n",
    "        this_pt = (node_csv.loc[item, 'y'],node_csv.loc[item, 'x'])\n",
    "\n",
    "        #this_color='slategrey'\n",
    "        #this_radius = 0.5\n",
    "        #this_opacity=0.3\n",
    "\n",
    "        for i in range (len(path_list)):\n",
    "            this_path = path_list[i]\n",
    "            if item in this_path:\n",
    "                this_color = colour_list[i]\n",
    "                this_criterion = criteria_list[i]\n",
    "                this_radius = 2\n",
    "                this_opacity = 0.5\n",
    "                \n",
    "       \n",
    "                folium.CircleMarker([this_pt[0],this_pt[1]], color=this_color, \n",
    "                                fill_color=this_color, fill_opacity=this_opacity, fill=True, \n",
    "                                radius=this_radius, opacity=this_opacity,\n",
    "                               popup = this_criterion).add_to(this_map)\n",
    "        \n",
    "    #-----RENDER ALL THE STRESSORS-----\n",
    "    if render_combined_stressors == True:\n",
    "        steps = 10\n",
    "        colormap = branca.colormap.linear.YlOrRd_09.scale(0.0, 1.5).to_step(steps)\n",
    "        gradient_map=defaultdict(dict)\n",
    "        for i in range(steps):\n",
    "            gradient_map[1/steps*i] = colormap.rgb_hex_str(1/steps*i)\n",
    "        gmap=gradient_map\n",
    "\n",
    "\n",
    "        node_df_for_stressors['Traffic signal']=0\n",
    "        node_df_for_stressors.loc[node_df_for_stressors[node_df_for_stressors['highway']=='traffic_signals'].index, 'Traffic signal']=1\n",
    "        \n",
    "        this_df = node_df_for_stressors[(node_df_for_stressors['Closest Poi Density_with distance decay']>15)|(node_df_for_stressors['traffic']>2)|(node_df_for_stressors['Traffic signal']==1)].copy()\n",
    "        # If we want to visualise only the hotspots of one stressor, delete the others, like in the following line (which should visualise only the POI density)\n",
    "        # this_df = node_df_for_stressors[node_df_for_stressors['Closest Poi Density_with distance decay']>15].copy()\n",
    "        this_df['Combined stressors']=1\n",
    "        HeatMap(data=this_df[['y', 'x', 'Combined stressors']].groupby(['y', 'x']).sum().reset_index().values.tolist(),gradient=gmap, radius=7, max_zoom=13).add_to(this_map)\n",
    "\n",
    "\n",
    "        '''\n",
    "        #----ADD THIS PART TO RENDER THE EXISTING HOTSPOTS----\n",
    "\n",
    "        steps = 10\n",
    "        colormap2 = branca.colormap.linear.YlOrRd_09.scale(0.0, 1).to_step(steps)\n",
    "        gradient_map2=defaultdict(dict)\n",
    "        for i in range(steps):\n",
    "            gradient_map2[1/steps*i] = colormap.rgb_hex_str(1/steps*i)\n",
    "        gmap2=gradient_map2\n",
    "\n",
    "        this_df = node_df_for_stressors[node_df_for_stressors['Hotspot']==1]\n",
    "        HeatMap(data=this_df[['y', 'x', 'Hotspot']].groupby(['y', 'x']).sum().reset_index().values.tolist(),gradient=gmap2, radius=9, max_zoom=13).add_to(this_map)\n",
    "        '''\n",
    "\n",
    "    this_map.save(this_title + \".html\" )\n",
    "    return(this_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_isochrones(this_graph,this_node,colour_list,time_rank_list):\n",
    "      \n",
    "    #----------Create a map to visualise the isochrones-----------\n",
    "    this_map = ox.folium.plot_graph_folium(G, graph_map=None, popup_attribute=None, tiles='cartodbpositron', zoom=1, location = [-33.8756785, 151.22353900000002],fit_bounds=True, edge_color='salmon', edge_width=0.5, edge_opacity=0.5)\n",
    "    this_map.save('isochrones for node X.html'.replace('X',str(this_node)))\n",
    "\n",
    "\n",
    "    cnt=0\n",
    "    for item in node_list:\n",
    "        this_pt = (node_csv.loc[item, 'y'],node_csv.loc[item, 'x'])\n",
    "\n",
    "        this_color='#605f6e'\n",
    "        this_radius = 0.1\n",
    "        this_opacity=0.3\n",
    "\n",
    "        if item in this_graph.nodes():\n",
    "            if item in colour_list:\n",
    "                this_color=colour_list[item]\n",
    "                this_radius = 20/time_rank_list[item]\n",
    "                this_opacity=0.5\n",
    "\n",
    "\n",
    "        folium.CircleMarker([this_pt[0],this_pt[1]], color=this_color, fill=True,\n",
    "                                radius=this_radius, opacity=this_opacity, fill_opacity = this_opacity, \n",
    "                                fill_color=this_color).add_to(this_map)\n",
    "\n",
    "\n",
    "\n",
    "    this_map.save('isochrones for node X.html'.replace('X',str(this_node)))\n",
    "\n",
    "    return(this_map)\n",
    "    #IFrame(src='./isochrones for node X.html'.replace('X',str(this_node)), width=1500, height=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ------  HOW TO APPLY THE FUNCTIONS  ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FOLLOW THE COMMON STEPS FOR ALL SCENARIOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the nodes within a 1800m area around the selected area (this is to help us with the visualisations \n",
    "# when we have a very large spatial database; later we will only visualise the points within the 1800m boundary\n",
    "# so that the created map is not very heavy)\n",
    "# We can increase the distance if it is needed, for larger routes\n",
    "# Put here the central point of the area of the analysis \n",
    "c_point = (-33.882882592547034, 151.2063073174587)\n",
    "my_area_graph = ox.graph_from_point((c_point[0],c_point[1]),dist=1800)\n",
    "\n",
    "G = my_area_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----The following part was used during testing the algorithm for selecting pairs of nodes \n",
    "# It creates a clickable map where each node can be clicked to see its ID \n",
    "# Activate if needed\n",
    "'''\n",
    "for_node_selection = ox.folium.plot_graph_folium(G, graph_map=None, popup_attribute=None, tiles='cartodbpositron', zoom=1, location = [-33.8756785, 151.22353900000002],fit_bounds=True, edge_color='salmon', edge_width=0.5, edge_opacity=0.5)\n",
    "for_node_selection.save(\"for node selection.html\" )\n",
    "\n",
    "cnt=0\n",
    "for item in node_list:\n",
    "    this_pt = (node_csv.loc[item, 'y'],node_csv.loc[item, 'x'])\n",
    "    this_color='slategrey'\n",
    "    this_radius = 0.5\n",
    "    this_opacity=0.3\n",
    "\n",
    "    folium.CircleMarker([this_pt[0],this_pt[1]], color=this_color, \n",
    "                            fill_color=this_color, fill_opacity=this_opacity, fill=True, \n",
    "                            radius=this_radius, opacity=this_opacity,\n",
    "                   popup = str(item)).add_to(for_node_selection)\n",
    "    \n",
    "for_node_selection.save(\"for node selection.html\" )\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src='./for node selection.html', width=1500, height=1500)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for hotspots of physiological responses\n"
     ]
    }
   ],
   "source": [
    "# ----IMPORT THE SPATIAL DATABASE---------\n",
    "# Put here the path where the file with the hotspots from Component 2 was saved \n",
    "# (after applying the methods of the file 'Cluster analysis').\n",
    "# This file should be in the spatial database and it should also contain the network nodes (with the hotspots of physiological responses, if available)\n",
    "hotspot_path = r'C:\\Users\\demdr\\Desktop\\Testing the thesis functions\\Project data\\Spatial database\\Urban network analysis_nodes_with_hotspot.csv'\n",
    "# Put here the path of the file containing the network links. This should be in the spatial database \n",
    "# created after applying the file 'Building the spatial database --Step 4-POI and OSM data fusion' from Component 1\n",
    "link_path = r'C:\\Users\\demdr\\Desktop\\Testing the thesis functions\\Project data\\Spatial database\\Urban network analysis_links.csv'\n",
    "# My old link path:  \n",
    "#r'D:\\UTS - Backup 30 Aug 2020\\Data\\Personal data-first tests\\Personal data-first tests\\Sydney urban network analysis_links.csv'\n",
    "node_csv = pd.read_csv(hotspot_path)\n",
    "link_csv = pd.read_csv(link_path)\n",
    "# The index of the 'node_csv' file should be the node index (a unique ID used in OSM data for representation of each node)\n",
    "node_csv = node_csv.set_index('Unnamed: 0.1')\n",
    "\n",
    "#Create a list that contains only the nodes within the area around the Central Station (to render the map more efficiently)\n",
    "#This point is not important for computation, only for visualization in the following map\n",
    "node_list = []\n",
    "for item in G.nodes():\n",
    "    if item in node_csv.index:\n",
    "        node_list.append(item)\n",
    "\n",
    "\n",
    "\n",
    "# ----USE DEFINITION 'calculate_POI_density_for_each_link'\n",
    "hotspot_column_name = 'Hotspot_Sum of EDR amplitudes_change' # Put another name here if needed\n",
    "# This column contains information regarding if the node is close to a hotspot of physiological responses or not \n",
    "# This column was created from the script designed for Component 2 (search the line \"#SAVE THE SPATIAL DATABASE WITH THE HOTSPOT INFO\")\n",
    "# The appropriate names following the column names used in the other script are the following: 'Hotspot_Sum of EDR amplitudes', 'Hotspot_Sum of EDR amplitudes_change'\n",
    "# Instead of the name 'Hotspot_Sum of EDR amplitudes_change' here, use the name Hotspot_Sum of EDR amplitudes' or 'Hotspot_Sum of EDR amplitudes_change' according to the \n",
    "# goal of the analysis\n",
    "num_of_users_col_name = 'Users in hotspot_Sum of EDR amplitudes_change' #Also modify this column name if needed. \n",
    "# This should be the column that stores information regarding the number of users in each hotspot\n",
    "\n",
    "\n",
    "\n",
    "# If there is no data regarding hotspots of physiological responses, add 2 empty columns anyway\n",
    "if hotspot_column_name not in node_csv.columns:\n",
    "    print('No data for hotspots of physiological responses')\n",
    "    node_csv[hotspot_column_name]=0\n",
    "    node_csv[num_of_users_col_name]=0\n",
    "    \n",
    "link_csv = calculate_POI_density_for_each_link(link_csv,node_csv,'Hotspot', 'Users in hotspot')\n",
    "\n",
    "\n",
    "\n",
    "# ----- ADD TIME ATTRIBUTE ----\n",
    "# Use the definition to add the time attribute\n",
    "# we put 4.5 km/h as the walking speed but this can change\n",
    "link_csv = add_time_attribute(link_csv, 4.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----make a df with selected columns for route optimization------\n",
    "link_csv_for_nx = create_csv_with_selected_attributes_for_optimisation(link_csv)\n",
    "# Add this if necessary for keeping only links (street segments) below/above a certain length\n",
    "link_csv_for_nx=link_csv_for_nx[link_csv_for_nx['length']<500]\n",
    "# We can also filter it according to hotspot users and keep only hotspots with many users (replace 0 with any other \n",
    "# desired number of users to do this)\n",
    "desired_number_of_users = 0\n",
    "link_csv_for_nx=link_csv_for_nx[link_csv_for_nx['Hotspot users']>=desired_number_of_users]\n",
    "\n",
    "\n",
    "# -----DATA TRANSFORMATION--------\n",
    "# Apply the definition for transformation of attributes for a list of selected parameters \n",
    "# Any other parameters (i.e. temperature, slope) should be added here in the same way in the future \n",
    "# if we wish to add them in the algorithm (after adding them to the spatial database)\n",
    "# We include a column for hotspots and hotspot users, even if it is filled with zeros\n",
    "attributes_for_transformation = ['Closest Poi Density_with distance decay','traffic','length','Traffic signals',\n",
    "                                'Hotspot']\n",
    "new_names = ['scaled Density','scaled Traffic','scaled Length','scaled Signals',\n",
    "             'scaled Hotspot']\n",
    "for i in range(len(attributes_for_transformation)):\n",
    "    this_attribute = attributes_for_transformation[i]\n",
    "    new_col_name = new_names[i]\n",
    "    transform_attributes(link_csv_for_nx,this_attribute, new_col_name)\n",
    "\n",
    "\n",
    "\n",
    "# ------PUT MODIFIERS-------\n",
    "# Apply definition for putting modifiers in the attributes:\n",
    "# The values of the modifiers determine the relative influence of each attribute \n",
    "# Now, all the modifiers have the same influence apart from length, which has a higher penalty \n",
    "# Therefore, length will be prioritised, but the other attributes will also be taken into account\n",
    "# To remove entirely some attributes, set their value to 0 (i.e. if we want only traffic and density, we can set the other values to 0)\n",
    "length_modifier = 30\n",
    "traffic_modifier = 20\n",
    "density_modifier = 20\n",
    "traffic_signal_modifier = 20\n",
    "hotspot_modifier = 20\n",
    "\n",
    "put_modifiers_in_the_attributes(link_csv_for_nx, length_modifier,traffic_modifier,density_modifier,\n",
    "                               traffic_signal_modifier,hotspot_modifier)\n",
    "\n",
    "\n",
    "#Create a df which contains only the nodes within the 1800m radius boundaries identified in the beginning\n",
    "# (we only use this for visualisation purposes)\n",
    "node_in_boundaries = pd.DataFrame()\n",
    "for i in node_list:\n",
    "    if i in node_csv.index:\n",
    "        node_in_boundaries = node_in_boundaries.append(node_csv.loc[i])\n",
    "\n",
    "\n",
    "# Construct a new graph from the link csv \n",
    "# The new graph has only the selected attributes (and the columns with the combined attributes)\n",
    "new_G = nx.from_pandas_edgelist(link_csv_for_nx, source='u',target='v', edge_attr=['scaled Traffic','scaled Length','scaled Density', 'scaled Signals','Combined attributes','Combined attributes and Hotspots','scaled Hotspot','time'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ADD THE STARTING AND ENDING POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 2 nodes as the starting and ending point\n",
    "# We could include here a small function for putting a GPS point as input and finding the closest node \n",
    "\n",
    "end_node = 1826240755\n",
    "initial_node = 25921196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TEST THE CREATED SCENARIOS\n",
    "Test one or more of the scenarios A, B or C \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test scenario A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route time: 26 minutes\n"
     ]
    }
   ],
   "source": [
    "# Examples for finding the shortest path between the nodes 'initial_node' and 'end_node', based on different attributes:\n",
    "\n",
    "\n",
    "# Find shortest path based on length\n",
    "s_p_length = find_shortest_path_ScenarioA(new_G, initial_node, end_node, 'scaled Length')\n",
    "# Find shortest path based on traffic\n",
    "s_p_traffic = find_shortest_path_ScenarioA(new_G, initial_node, end_node, 'scaled Traffic')\n",
    "# Find shortest path based on density\n",
    "s_p_density = find_shortest_path_ScenarioA(new_G, initial_node, end_node, 'scaled Density')\n",
    "# Find shortest path based on signals\n",
    "s_p_signal = find_shortest_path_ScenarioA(new_G, initial_node, end_node, 'scaled Signals')\n",
    "# Find shortest path based on all the criteria together\n",
    "s_p_alltogether = find_shortest_path_ScenarioA(new_G, initial_node, end_node, 'Combined attributes')\n",
    "\n",
    "# Find the route time: Put here the name of the path and the desired walking speed (in km/h)\n",
    "route_time_for_length_based_path = calculate_route_time(s_p_length,4.5)\n",
    "# Do the same for the other paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. Test scenario B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route time: 33 minutes\n"
     ]
    }
   ],
   "source": [
    "# Find shortest path based on all together + Hotspots\n",
    "s_p_alltogether_and_hotspots = find_shortest_path_ScenarioA(new_G, initial_node, end_node, 'Combined attributes and Hotspots')\n",
    "#Find route time (for walking with 4.5km speed)\n",
    "route_time_for_combined_stressors_and_hotspots = calculate_route_time(s_p_alltogether_and_hotspots,4.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Scenario D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route time: 33 minutes\n"
     ]
    }
   ],
   "source": [
    "# The step_for_isochrones is 5 minutes (so all the nodes that are within 5 minutes from the start will have the same colour;\n",
    "# the nodes that are more than 5 and within 10 minutes from the start will have another colour, and so on\n",
    "step_for_isochrones = 5 \n",
    "# Increase this value if needed\n",
    "end_time = 70\n",
    "trip_times = list(np.arange(step_for_isochrones,end_time,step_for_isochrones))\n",
    "\n",
    "\n",
    "# Put True here to visualise the isochrones for this pair of nodes, False to exclude the visualisation\n",
    "create_isochrones_for_a_node = create_isochrones(new_G, trip_times,initial_node, True,\n",
    "                                                length_modifier,traffic_modifier,density_modifier,\n",
    "                                                 traffic_signal_modifier,hotspot_modifier)\n",
    "\n",
    "# Use the extracted data to visualise the isochrones \n",
    "isochrone_graph = create_isochrones_for_a_node[0]\n",
    "node_iso_clrs = create_isochrones_for_a_node[1]\n",
    "node_iso_timeranks = create_isochrones_for_a_node[2]\n",
    "\n",
    "# Use the new graph to find the shortest path, with all the criteria and time-penalty\n",
    "s_p_timecorrected=nx.shortest_path(isochrone_graph, source=initial_node, target=end_node, weight='Time-corrected combined attributes', method='dijkstra')\n",
    "#Find route time (for walking with 4.5km speed)\n",
    "route_time_for_combined_stressors_and_time_penalty = calculate_route_time(s_p_timecorrected,4.5)\n",
    "\n",
    "\n",
    "isochrone_map = visualise_isochrones(new_G,initial_node, node_iso_clrs,node_iso_timeranks)\n",
    "#This can be activated to display the isochrone map\n",
    "#IFrame(src='./isochrones for node X.html'.replace('X',str(initial_node)), width=1500, height=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test scenario B+D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route time: 39 minutes\n"
     ]
    }
   ],
   "source": [
    "# The step is 5 minutes (so all the nodes that are within 5 minutes from the start will have the same colour;\n",
    "# the nodes that are more than 5 and within 10 minutes from the start will have another colour, and so on\n",
    "step_for_isochrones = 5 \n",
    "# Increase this value if needed\n",
    "end_time = 70\n",
    "trip_times = list(np.arange(step_for_isochrones,end_time,step_for_isochrones))\n",
    "\n",
    "\n",
    "# Put True here to visualise the isochrones for this pair of nodes, False to exclude the visualisation\n",
    "create_isochrones_for_a_node = create_isochrones(new_G, trip_times,initial_node, True,\n",
    "                                                length_modifier,traffic_modifier,density_modifier,\n",
    "                                                 traffic_signal_modifier,hotspot_modifier)\n",
    "# Use the extracted data to visualise the isochrones \n",
    "isochrone_graph = create_isochrones_for_a_node[0]\n",
    "node_iso_clrs = create_isochrones_for_a_node[1]\n",
    "node_iso_timeranks = create_isochrones_for_a_node[2]\n",
    "\n",
    "# Use the new graph to find the shortest path, with all the criteria AND time-penalty AND hotspots\n",
    "s_p_timecorrected_with_hotspots=nx.shortest_path(isochrone_graph, source=initial_node, target=end_node, weight='Time-corrected combined attributes with hotspots', method='dijkstra')\n",
    "\n",
    "#Find route time (for walking with 4.5km speed)\n",
    "route_time_for_combined_stressors_and_time_penalty_and_hotspots = calculate_route_time(s_p_timecorrected_with_hotspots,4.5)\n",
    "\n",
    "isochrone_map = visualise_isochrones(new_G,initial_node, node_iso_clrs,node_iso_timeranks)\n",
    "#Same as above; This can be activated to display the isochrone map\n",
    "#IFrame(src='./isochrones for node X.html'.replace('X',str(initial_node)), width=1500, height=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Visualise the created path(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"1500\"\n",
       "            src=\"./shortest path - length.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16aca8df9c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of using the definition for visualising one path \n",
    "\n",
    "# Display the created map: visualise shortest path according to length\n",
    "# We can use this to visualise paths for the following: \n",
    "# s_p_traffic,s_p_signal,s_p_density,s_p_alltogether, s_p_alltogether_and_hotspots, \n",
    "# s_p_timecorrected, s_p_timecorrected_with_hotspots\n",
    "\n",
    "title = 'shortest path - length'\n",
    "display_title = './' + title + '.html'\n",
    "shortest_path_based_on_length = visualise_shortest_path(G, title, s_p_length, 'tomato',\n",
    "                                                       True,node_in_boundaries)\n",
    "IFrame(src=display_title, width=1500, height=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"1500\"\n",
       "            src=\"./Compare the generated shortest paths2.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16acef19608>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the following code for visual comparison of the generated shortest paths, if we have \n",
    "# many paths to compare (generated by using different criteria in scenario A, or using other scenarios)\n",
    "title = 'Compare the generated shortest paths2'\n",
    "display_title = './' + title + '.html'\n",
    "# Put here the paths that we want to compare\n",
    "paths = [s_p_length,s_p_traffic,s_p_density,s_p_signal,s_p_alltogether,s_p_alltogether_and_hotspots]\n",
    "colours = ['tomato','teal','darkseagreen','greenyellow','crimson','black']\n",
    "criteria = ['Length-based optimisation','Traffic-based optimisation','Density-based optimisation','Traffic signal-based optimisation',\n",
    "                'All criteria-based optimisation','All criteria-based optimisation plus hotspots']\n",
    "\n",
    "compare_paths = create_map_for_comparison_of_generated_paths(G, title, paths,colours,criteria,\n",
    "                                                            True,node_in_boundaries)\n",
    "IFrame(src=display_title, width=1500, height=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
